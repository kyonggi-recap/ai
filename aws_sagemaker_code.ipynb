{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#summarization deploy \n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'facebook/bart-large-cnn',\n",
    "\t'HF_TASK':'summarization'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\ttransformers_version='4.37.0',\n",
    "\tpytorch_version='2.1.0',\n",
    "\tpy_version='py310',\n",
    "\tenv=hub,\n",
    "\trole=role, \n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1, # number of instances\n",
    "\tinstance_type='ml.m5.xlarge' # ec2 instance type\n",
    ")\n",
    "\n",
    "predictor.predict({\n",
    "\t\"inputs\": \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#summarization endpoint call \n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# SageMaker Runtime í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "runtime = boto3.client(\"sagemaker-runtime\", region_name=\"ap-northeast-2\")  # ì„œìš¸ ë¦¬ì „ ì˜ˆì‹œ\n",
    "\n",
    "# ì—”ë“œí¬ì¸íŠ¸ ì´ë¦„\n",
    "endpoint_name = \"huggingface-pytorch-inference-2025-05-14-10-53-09-680\"  # ì—¬ê¸°ì— ë³¸ì¸ì˜ ì—”ë“œí¬ì¸íŠ¸ ì´ë¦„ì„ ë„£ìœ¼ì„¸ìš”\n",
    "\n",
    "# ì…ë ¥ ë°ì´í„° (ì˜ˆì‹œ: HuggingFace-style JSON)\n",
    "input_data = {\n",
    "    \"inputs\": \"The tower is 324 metres (1,063 ft) tall, about the same height as an 81-storey building, and the tallest structure in Paris. Its base is square, measuring 125 metres (410 ft) on each side. During its construction, the Eiffel Tower surpassed the Washington Monument to become the tallest man-made structure in the world, a title it held for 41 years until the Chrysler Building in New York City was finished in 1930. It was the first structure to reach a height of 300 metres. Due to the addition of a broadcasting aerial at the top of the tower in 1957, it is now taller than the Chrysler Building by 5.2 metres (17 ft). Excluding transmitters, the Eiffel Tower is the second tallest free-standing structure in France after the Millau Viaduct.\"\n",
    "}\n",
    "\n",
    "# JSON ì§ë ¬í™”\n",
    "payload = json.dumps(input_data)\n",
    "\n",
    "# Endpoint í˜¸ì¶œ\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",  # ëŒ€ë¶€ë¶„ì˜ NLP ëª¨ë¸ì€ JSON í˜•ì‹ ì‚¬ìš©\n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ë””ì½”ë”©\n",
    "result = response[\"Body\"].read().decode(\"utf-8\")\n",
    "\n",
    "# ì¶œë ¥ ê²°ê³¼ í™•ì¸\n",
    "print(\"Inference result:\")\n",
    "print(result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#translation model ko-> en deploy\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'facebook/nllb-200-distilled-600M',\n",
    "\t'HF_TASK':'translation'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\ttransformers_version='4.37.0',\n",
    "\tpytorch_version='2.1.0',\n",
    "\tpy_version='py310',\n",
    "\tenv=hub,\n",
    "\trole=role,\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1, # number of instances\n",
    "\tinstance_type='ml.m5.xlarge', # ec2 instance type\n",
    "    src_lang = \"ko\",   # ì†ŒìŠ¤ ì–¸ì–´: í•œêµ­ì–´(ISO 639-3 ì½”ë“œ)\n",
    "    tgt_lang = \"en\",\n",
    ")\n",
    "\n",
    "predictor.predict({'inputs': \"\"\"íŠ¸ëŸ¼í”„ ë¯¸êµ­ ëŒ€í†µë ¹ì´ ìºë‚˜ë‹¤ì™€ ë©•ì‹œì½”ì— ëŒ€í•œ ê´€ì„¸ë¥¼ ì•½ í•œ ë‹¬ê°„ ìœ ì˜ˆí•˜ê¸°ë¡œ í–ˆì§€ë§Œ, ê´€ì„¸ ì •ì±…ì„ ë‘˜ëŸ¬ì‹¼ ë¶ˆí™•ì‹¤ì„±ì´ íˆ¬ì ì‹¬ë¦¬ë¥¼ ì§“ëˆ„ë¥´ë©´ì„œ ë‰´ìš• ì¦ì‹œì˜ 3ëŒ€ ì£¼ê°€ì§€ìˆ˜ê°€ ë™ë°˜ í•˜ë½í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë‰´ìš• ì¦ê¶Œ ê±°ë˜ì†Œì—ì„œ ë‚˜ìŠ¤ë‹¥ ì¢…í•© ì§€ìˆ˜ëŠ” ì „ì¥ë³´ë‹¤ 483.48í¬ì¸íŠ¸, 2.61% ì£¼ì €ì•‰ì€ 18,069.26ì— ì¥ì„ ë§ˆì³¤ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìŠ¤íƒ ë”ë“œ ì•¤ë“œ í‘¸ì–´ìŠ¤ 500ì§€ìˆ˜ëŠ” 104.11í¬ì¸íŠ¸, 1.78% ê¸‰ë½í•œ 5,738.52ì—, ë‹¤ìš°ì¡´ìŠ¤30ì‚°ì—…í‰ê· ì§€ìˆ˜ëŠ” 427.51í¬ì¸íŠ¸, 0.99% ë–¨ì–´ì§„ 42,579.08ë¡œ ê±°ë˜ë¥¼ ë§ˆê°í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŠ” íŠ¸ëŸ¼í”„ê°€ ë¯¸êµ­Â·ë©•ì‹œì½”Â·ìºë‚˜ë‹¤ ë¬´ì—­ í˜‘ì • ì ìš© í’ˆëª©ì— ë‹¤ìŒ ë‹¬ 2ì¼ê¹Œì§€ 25% ê´€ì„¸ë¥¼ ë©´ì œí•˜ê¸°ë¡œ í–ˆì§€ë§Œ, íˆ¬ììë“¤ì€ ì •ì±… ë°©í–¥ì´ ë„ˆë¬´ ê°€ë³€ì ì´ë¼ëŠ” ë° ë¶ˆì•ˆì„ ëŠë‚€ ê²ƒìœ¼ë¡œ í’€ì´ë©ë‹ˆë‹¤.\n",
    "\n",
    "ë˜ í—¤ì§€í€ë“œ ì„¤ë¦½ìë¡œ, íŠ¸ëŸ¼í”„ì˜ ì •ì±…ì— ì œë™ì„ ê±¸ì–´ì¤„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëë˜ ìŠ¤ì½§ ë² ì„¼íŠ¸ ì¬ë¬´ì¥ê´€ì´ ìºë‚˜ë‹¤ ì´ë¦¬ë¥¼ ë¹„í•˜í•˜ëŠ” ë“± íŠ¸ëŸ¼í”„ì™€ ìœ ì‚¬í•œ ì–´ë²•ì„ êµ¬ì‚¬í•˜ì ì›”ê°€ëŠ” ì‹¤ë§í•˜ëŠ” ë¶„ìœ„ê¸°ì˜€ìŠµë‹ˆë‹¤.\n",
    "\"\"\",\n",
    "                   'parameters': {'src_lang': 'ko', 'tgt_lang' : 'en'}})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#trainslation call ko->en\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# SageMaker Runtime í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "runtime = boto3.client(\"sagemaker-runtime\", region_name=\"ap-northeast-2\")  # ë¦¬ì „ì€ ìì‹ ì˜ ê²ƒìœ¼ë¡œ ìˆ˜ì •\n",
    "\n",
    "# ì—”ë“œí¬ì¸íŠ¸ ì´ë¦„\n",
    "endpoint_name = \"huggingface-pytorch-inference-2025-05-14-10-58-26-686\"\n",
    "\n",
    "# ì…ë ¥ êµ¬ì„±\n",
    "input_payload = {\n",
    "    \"inputs\": \"\"\"íŠ¸ëŸ¼í”„ ë¯¸êµ­ ëŒ€í†µë ¹ì´ ìºë‚˜ë‹¤ì™€ ë©•ì‹œì½”ì— ëŒ€í•œ ê´€ì„¸ë¥¼ ì•½ í•œ ë‹¬ê°„ ìœ ì˜ˆí•˜ê¸°ë¡œ í–ˆì§€ë§Œ, ê´€ì„¸ ì •ì±…ì„ ë‘˜ëŸ¬ì‹¼ ë¶ˆí™•ì‹¤ì„±ì´ íˆ¬ì ì‹¬ë¦¬ë¥¼ ì§“ëˆ„ë¥´ë©´ì„œ ë‰´ìš• ì¦ì‹œì˜ 3ëŒ€ ì£¼ê°€ì§€ìˆ˜ê°€ ë™ë°˜ í•˜ë½í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ë‰´ìš• ì¦ê¶Œ ê±°ë˜ì†Œì—ì„œ ë‚˜ìŠ¤ë‹¥ ì¢…í•© ì§€ìˆ˜ëŠ” ì „ì¥ë³´ë‹¤ 483.48í¬ì¸íŠ¸, 2.61% ì£¼ì €ì•‰ì€ 18,069.26ì— ì¥ì„ ë§ˆì³¤ìŠµë‹ˆë‹¤.\n",
    "\n",
    "ìŠ¤íƒ ë”ë“œ ì•¤ë“œ í‘¸ì–´ìŠ¤ 500ì§€ìˆ˜ëŠ” 104.11í¬ì¸íŠ¸, 1.78% ê¸‰ë½í•œ 5,738.52ì—, ë‹¤ìš°ì¡´ìŠ¤30ì‚°ì—…í‰ê· ì§€ìˆ˜ëŠ” 427.51í¬ì¸íŠ¸, 0.99% ë–¨ì–´ì§„ 42,579.08ë¡œ ê±°ë˜ë¥¼ ë§ˆê°í–ˆìŠµë‹ˆë‹¤.\n",
    "\n",
    "ì´ëŠ” íŠ¸ëŸ¼í”„ê°€ ë¯¸êµ­Â·ë©•ì‹œì½”Â·ìºë‚˜ë‹¤ ë¬´ì—­ í˜‘ì • ì ìš© í’ˆëª©ì— ë‹¤ìŒ ë‹¬ 2ì¼ê¹Œì§€ 25% ê´€ì„¸ë¥¼ ë©´ì œí•˜ê¸°ë¡œ í–ˆì§€ë§Œ, íˆ¬ììë“¤ì€ ì •ì±… ë°©í–¥ì´ ë„ˆë¬´ ê°€ë³€ì ì´ë¼ëŠ” ë° ë¶ˆì•ˆì„ ëŠë‚€ ê²ƒìœ¼ë¡œ í’€ì´ë©ë‹ˆë‹¤.\n",
    "\n",
    "ë˜ í—¤ì§€í€ë“œ ì„¤ë¦½ìë¡œ, íŠ¸ëŸ¼í”„ì˜ ì •ì±…ì— ì œë™ì„ ê±¸ì–´ì¤„ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ëë˜ ìŠ¤ì½§ ë² ì„¼íŠ¸ ì¬ë¬´ì¥ê´€ì´ ìºë‚˜ë‹¤ ì´ë¦¬ë¥¼ ë¹„í•˜í•˜ëŠ” ë“± íŠ¸ëŸ¼í”„ì™€ ìœ ì‚¬í•œ ì–´ë²•ì„ êµ¬ì‚¬í•˜ì ì›”ê°€ëŠ” ì‹¤ë§í•˜ëŠ” ë¶„ìœ„ê¸°ì˜€ìŠµë‹ˆë‹¤.\n",
    "\"\"\",\n",
    "    \"parameters\": {\n",
    "        \"src_lang\": \"ko\",\n",
    "        \"tgt_lang\": \"en\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# JSON ì§ë ¬í™”\n",
    "payload = json.dumps(input_payload)\n",
    "\n",
    "# Endpoint í˜¸ì¶œ\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ë””ì½”ë”©\n",
    "result = response['Body'].read().decode('utf-8')\n",
    "print(\"Prediction result:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#translation model en-> ko deploy\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker.huggingface import HuggingFaceModel\n",
    "\n",
    "try:\n",
    "\trole = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "\tiam = boto3.client('iam')\n",
    "\trole = iam.get_role(RoleName='sagemaker_execution_role')['Role']['Arn']\n",
    "\n",
    "# Hub Model configuration. https://huggingface.co/models\n",
    "hub = {\n",
    "\t'HF_MODEL_ID':'facebook/nllb-200-distilled-600M',\n",
    "\t'HF_TASK':'translation'\n",
    "}\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "\ttransformers_version='4.37.0',\n",
    "\tpytorch_version='2.1.0',\n",
    "\tpy_version='py310',\n",
    "\tenv=hub,\n",
    "\trole=role,\n",
    ")\n",
    "\n",
    "# deploy model to SageMaker Inference\n",
    "predictor = huggingface_model.deploy(\n",
    "\tinitial_instance_count=1, # number of instances\n",
    "\tinstance_type='ml.m5.2xlarge', # ec2 instance type\n",
    "    src_lang = \"en\",   # ì†ŒìŠ¤ ì–¸ì–´: í•œêµ­ì–´(ISO 639-3 ì½”ë“œ)\n",
    "    tgt_lang = \"ko\",\n",
    ")\n",
    "\n",
    "predictor.predict({'inputs': \"\"\"the President of the United States, had postponed tariffs on Canada and Mexico for about a month, but the uncertainty surrounding the tariff policy had crushed the investment core, and the 3rd largest indicator of the New York Stock Exchange had collapsed along with it.The NASDAQ index on the New York Stock Exchange ended the chapter at 483.48 points above the previous one, 2.61% below the 18,069.26 point.The Standard & Poor's 500 index was 104.11 points, 1.78% below the 5,738.52 point, while Dow Jones's 30 business index closed the deal at 427.51 points, 0.99% below the 579.08 point.This led to Trump's decision to exempt from 42,25% on items that applied to US-Mexico-Canada trade until the next 2 days, investors felt uncertainty that the direction of the trade would be moving forward.\n",
    "\"\"\",\n",
    "                   'parameters': {'src_lang': 'en', 'tgt_lang' : 'ko'}})\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#trainslation call en->ko\n",
    "import boto3\n",
    "import json\n",
    "\n",
    "# SageMaker Runtime í´ë¼ì´ì–¸íŠ¸ ìƒì„±\n",
    "runtime = boto3.client(\"sagemaker-runtime\", region_name=\"ap-northeast-2\")  # ë¦¬ì „ì€ ìì‹ ì˜ ê²ƒìœ¼ë¡œ ìˆ˜ì •\n",
    "\n",
    "# ì—”ë“œí¬ì¸íŠ¸ ì´ë¦„\n",
    "endpoint_name = \"huggingface-pytorch-inference-2025-05-14-11-14-29-162\"\n",
    "\n",
    "# ì…ë ¥ êµ¬ì„±\n",
    "input_payload = {\n",
    "    \"inputs\": \"\"\"Trump, the President of the United States, had postponed tariffs on Canada and Mexico for about a month, but the uncertainty surrounding the tariff policy had crushed the investment core, and the New York Stock Exchange's 3rd largest indicator had collapsed along with it.The NASDAQ index on the New York Stock Exchange ended the chapter at 483.48 points above the previous one, 2.61% below the 18,069.26 point.The Standard & Poor's 500 index was 104.11 points, 1.78% below the 5,738.52 point, while Dow Jones's 30 business index closed the deal at 427.51 points, 0.99% below the 42,579.08 point.This led to Trump's decision to exempt from tariffs of 25% on items that applied to US-Mexico-Canada trade until the next 2 days, but investors felt uncertainty that the direction of the\n",
    "\"\"\",\n",
    "    \"parameters\": {\n",
    "        \"src_lang\": \"eng_Latn\",\n",
    "        \"tgt_lang\": \"kor_Hang\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# JSON ì§ë ¬í™”\n",
    "payload = json.dumps(input_payload)\n",
    "\n",
    "# Endpoint í˜¸ì¶œ\n",
    "response = runtime.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=payload\n",
    ")\n",
    "\n",
    "# ê²°ê³¼ ë””ì½”ë”©\n",
    "result = response['Body'].read().decode('utf-8')\n",
    "print(\"Prediction result:\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#ì¶”ì²œ \n",
    "import openai\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# âœ… OpenAI API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ë¡œ ì„¤ì •í•´ë„ ë¨)\n",
    "openai.api_key = \"\"  # ì•ˆì „í•˜ê²Œ í™˜ê²½ë³€ìˆ˜ë¡œ ê´€ë¦¬í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n",
    "\n",
    "# âœ… ì„ë² ë”© í•¨ìˆ˜ ì •ì˜\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=[text],\n",
    "        model=model\n",
    "    )\n",
    "    return response.data[0].embedding\n",
    "\n",
    "def get_batch_embeddings(texts, model=\"text-embedding-3-small\"):\n",
    "    response = openai.embeddings.create(\n",
    "        input=texts,\n",
    "        model=model\n",
    "    )\n",
    "    return [item.embedding for item in response.data]\n",
    "\n",
    "# âœ… ì…ë ¥ ë°ì´í„°\n",
    "texts = [\n",
    "    \"Illustration of the REaLTabFormer model...\",\n",
    "    \"Predicting human mobility holds significant...\",\n",
    "    \"As the economies of Southeast Asia continue...\"\n",
    "    # ì´ 10ê°œ ë¬¸ì¥ê¹Œì§€ í™•ì¥ ê°€ëŠ¥\n",
    "]\n",
    "\n",
    "liked_texts = [\n",
    "    \"I enjoy reading about advanced machine learning models and their applications.\",\n",
    "    \"Human mobility prediction is fascinating, especially when using transformer-based models.\"\n",
    "]\n",
    "\n",
    "# âœ… liked ì„ë² ë”© í‰ê·  ê³„ì‚°\n",
    "liked_embeddings = get_batch_embeddings(liked_texts)\n",
    "liked_tensor = torch.tensor(liked_embeddings)\n",
    "mean_liked_embedding = torch.mean(liked_tensor, dim=0)\n",
    "\n",
    "# âœ… texts ì„ë² ë”© ê³„ì‚°\n",
    "text_embeddings = get_batch_embeddings(texts)\n",
    "text_tensors = torch.tensor(text_embeddings)\n",
    "\n",
    "# âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°\n",
    "similarities = F.cosine_similarity(text_tensors, mean_liked_embedding.unsqueeze(0), dim=1)\n",
    "\n",
    "# âœ… ê°€ì¥ ìœ ì‚¬í•œ ë¬¸ì¥ ì¶”ì¶œ\n",
    "most_similar_index = torch.argmax(similarities).item()\n",
    "most_similar_sentence = texts[most_similar_index]\n",
    "\n",
    "# âœ… ì¶œë ¥\n",
    "print(f\"\\nğŸ“Œ Most similar sentence:\\n{most_similar_sentence}\")\n",
    "print(f\"ğŸ”— Similarity score: {similarities[most_similar_index].item():.4f}\")\n",
    "\n",
    "# âœ… ëª¨ë“  ìœ ì‚¬ë„ ì¶œë ¥\n",
    "print(\"\\nğŸ” All similarity scores:\")\n",
    "for i, (text, score) in enumerate(zip(texts, similarities)):\n",
    "    print(f\"Sentence {i+1}: {score.item():.4f} - {text[:60]}...\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
